{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9941f322-f360-4ca0-afc4-d829a91b242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc397a98-15a4-47b2-96b6-2c7d5614d5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(28 * 28, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65975112-bd16-4394-b8dd-dc2586f72271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c7e7f69-609c-4cac-9cea-10474c72f049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the loss\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6747233-7ffa-440e-bd68-f4800c673a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST('data', \n",
    "                            train=True,\n",
    "                            download=True, \n",
    "                            transform=transforms.ToTensor())\n",
    "train, val = random_split(train_data, [55000, 5000])\n",
    "train_loader = DataLoader(train, batch_size=32)\n",
    "val_loader = DataLoader(val, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ed5782-40cf-4f41-a464-96ba5bef0e14",
   "metadata": {},
   "source": [
    " ### Training and validation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166fb7d2-6fc6-46e8-a4bb-51e8e9aaee28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 1, train loss: 1.32\n",
      " Epoch 1, validation loss: 0.91\n",
      " Epoch 2, train loss: 0.41\n",
      " Epoch 2, validation loss: 0.38\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epochs = 5\n",
    "for epoch in range (epochs):\n",
    "    losses = list()\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        \n",
    "        # x: b * 1 * 28 * 28\n",
    "        \n",
    "        b = x.size(0)\n",
    "        x= x.view(b, -1)\n",
    "        \n",
    "        # 1. Forward\n",
    "        l = model(x)\n",
    "        \n",
    "        # 2. Objective function \n",
    "        j = loss(l, y)\n",
    "        \n",
    "        # 3. Cleaning the gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # 4. Partial derivatives of J \n",
    "        j.backward()\n",
    "        \n",
    "        # 5. Step the optimizer\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        losses.append(j.item())\n",
    "        \n",
    "    print(f' Epoch {epoch + 1}, train loss: {torch.tensor(losses).mean() :.2f}')\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        \n",
    "        # x: b * 1 * 28 * 28\n",
    "        \n",
    "        b = x.size(0)\n",
    "        x= x.view(b, -1)\n",
    "        \n",
    "        # 1. Forward\n",
    "        with torch.no_grad():\n",
    "            l = model(x)  # the l is a logit\n",
    "        \n",
    "        # 2. Objective function \n",
    "        j = loss(l, y)\n",
    "        \n",
    "        losses.append(j.item())\n",
    "        \n",
    "    print(f' Epoch {epoch + 1}, validation loss: {torch.tensor(losses).mean() :.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2f8880-4acd-4f32-9c2c-61b4dacefcc6",
   "metadata": {},
   "source": [
    "### Improving the Model using Residual Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fdf3e7-4c46-4a7e-ab9d-bf2c3012fd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a more flexible model\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(28 * 28, 64)\n",
    "        self.l2 = nn.Linear(64, 64)\n",
    "        self.l3 = nn.Linear(64, 10)\n",
    "        self.do = nn.Dropout(0,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h1 = nn.functional.relu(self.l1(x))\n",
    "        h2 = nn.functional.relu(self.l2(h1))\n",
    "        do = self.do(h2 + h1)\n",
    "        logits = self.l3(do)\n",
    "        return logits\n",
    "        \n",
    "Model = ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d987d45-0ae5-47ce-b449-cff064ea5ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the optimizer \n",
    "Params = Model.parameters()\n",
    "Optimizer = optim.SGD(Params, lr = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a2d1e-c031-4a27-b082-80f8f31341b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss\n",
    "Loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b78b50c-689a-4da6-b647-b0333b010cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My training and validation loops\n",
    "epochs = 5\n",
    "for epoch in range (epochs):\n",
    "    Losses = list()\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        \n",
    "        # x: b * 1 * 28 * 28\n",
    "        \n",
    "        b = x.size(0)\n",
    "        x= x.view(b, -1)\n",
    "        \n",
    "        # 1. Forward\n",
    "        l = Model(x)\n",
    "        \n",
    "        # 2. Objective function \n",
    "        j = Loss(l, y)\n",
    "        \n",
    "        # 3. Cleaning the gradients\n",
    "        Model.zero_grad()\n",
    "        \n",
    "        # 4. Partial derivatives of J \n",
    "        j.backward()\n",
    "        \n",
    "        # 5. Step the optimizer\n",
    "        Optimizer.step()\n",
    "        \n",
    "        \n",
    "        Losses.append(j.item())\n",
    "        \n",
    "    print(f' Epoch {epoch + 1}, train loss: {torch.tensor(Losses).mean() :.2f}')\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        \n",
    "        # x: b * 1 * 28 * 28\n",
    "        \n",
    "        b = x.size(0)\n",
    "        x= x.view(b, -1)\n",
    "        \n",
    "        # 1. Forward\n",
    "        with torch.no_grad():\n",
    "            l = Model(x)  # the l is a logit\n",
    "        \n",
    "        # 2. Objective function \n",
    "        j = Loss(l, y)\n",
    "        \n",
    "        Losses.append(j.item())\n",
    "        \n",
    "    print(f' Epoch {epoch + 1}, validation loss: {torch.tensor(Losses).mean() :.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b511a0-9c07-4099-9bf2-3493e494840c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
